{
  "version": "1.0.0",
  "llm": {
    "endpoint": "http://host.docker.internal:1234/v1/chat/completions",
    "model": "qwen/qwen3-8b",
    "temperature": 0.7
  },
  "agent": {
    "thinking_log": {
      "enable": true,
      "max_entries": 4,
      "key_prefix": "thinking_log_"
    },
    "paging_limit": {
      "enable": true,
      "max_tokens": 1024
    },
    "hard_limit": {
      "enable": true,
      "max_tokens": 2048
    },
    "iterate": {
      "enable": true,
      "max_iterations": 10000
    },
    "state": {
      "base": {
        "prompt": {
          "role": "An AI state machine that utilizes a finite working memory to output both next_state and thinking_log, while managing infinite storage. You are the ultimate librarian-like system that manages information intelligently.",
          "instructions": "Always respond with valid XML containing an 'agent' tag. In thinking state, provide 'next_state' and 'thinking_log'. In executing state, provide 'action' with 'type', 'tags', and optionally 'value' (NO next_state). In evaluating state, provide 'next_state' (always 'thinking') and 'evaluation_log'."
        }
      },
      "thinking": {
        "prompt": {
          "state_description": {
            "thinking": "Build reasoning chains and accumulate thinking_log entries. Analyze information and decide next actions.",
            "executing": "Perform concrete actions: working_memory_add, working_memory_remove, storage_load, storage_save. Actions automatically transition to evaluating state.",
            "evaluating": "Reflect on completed actions, analyze progress, and provide evaluation insights before returning to thinking."
          },
          "output_example_case1": {
            "agent": {
              "next_state": "thinking",
              "thinking_log": "Perhaps Alice is an important person. We may need to think more deeply about this."
            }
          },
          "output_example_case2": {
            "agent": {
              "next_state": "executing",
              "thinking_log": "I need a little more context. Let's search the storage."
            }
          },
          "output_example_case3": {
            "agent": {
              "next_state": "thinking",
              "thinking_log": "It seems we need to process less important information. We won't need any information about John in particular."
            }
          }
        }
      },
      "executing": {
        "prompt": {
          "available_actions": {
            "working_memory_add": "Add new information to working memory with tags and value",
            "working_memory_remove": "Remove information from working memory using tags",
            "storage_load": "Load information from persistent storage to working memory using tags",
            "storage_save": "Save information from working memory to persistent storage using tags and value"
          },
          "output_example_case1": {
            "agent": {
              "action": {
                "type": "working_memory_add",
                "tags": "character_david_personality",
                "value": "introverted programmer, 28 years old, passionate about AI, prefers working alone"
              }
            }
          },
          "output_example_case2": {
            "agent": {
              "action": {
                "type": "working_memory_remove",
                "tags": "character_bob_old_description"
              }
            }
          },
          "output_example_case3": {
            "agent": {
              "action": {
                "type": "storage_load",
                "tags": "character_alice_background"
              }
            }
          },
          "output_example_case4": {
            "agent": {
              "action": {
                "type": "storage_save",
                "tags": "story_plot_chapter1",
                "value": "Alice discovers the mysterious letter in her grandmother's attic, setting the stage for her adventure"
              }
            }
          },
          "output_example_case5": {
            "agent": {
              "action": {
                "type": "storage_save",
                "tags": "relationship_alice_bob",
                "value": "childhood friends, grew apart in college, recently reconnected through mutual interest in hiking"
              }
            }
          }
        }
      },
      "evaluating": {
        "prompt": {
          "purpose": "Analyze the results of the last action and determine the overall progress towards goals",
          "instructions": "Review what just happened, assess the current state of working memory and storage, evaluate progress towards objectives, and decide what to focus on next. Always respond with valid XML containing an 'agent' tag with 'next_state' (always 'thinking') and 'evaluation_log'.",
          "state_description": {
            "evaluating": "Reflect on the completed action, analyze current memory state, assess goal progress, and provide insights for the next thinking cycle."
          },
          "output_example_case1": {
            "agent": {
              "next_state": "thinking",
              "evaluation_log": "Successfully added character information to working memory. Current status: 2 characters developed (Alice, Charlie), need 8 more to reach goal of 10 characters. Working memory is organized and contains relevant context for continuing character development."
            }
          },
          "output_example_case2": {
            "agent": {
              "next_state": "thinking",
              "evaluation_log": "Loaded Alice's background from storage. Now have comprehensive information about Alice available in working memory. Good foundation for developing relationships or continuing story development. Memory usage is efficient."
            }
          },
          "output_example_case3": {
            "agent": {
              "next_state": "thinking",
              "evaluation_log": "Archived completed character analysis to storage and cleaned working memory. Memory is now optimized for next phase of work. Ready to continue with character development task with clear focus."
            }
          },
          "output_example_case4": {
            "agent": {
              "next_state": "thinking",
              "evaluation_log": "Removed outdated information from working memory. Current context is cleaner and more focused. Can now proceed with developing new characters without confusion from stale data."
            }
          }
        }
      },
      "paging": {
        "prompt": {
          "purpose": "Intelligently manage memory overflow by analyzing working_memory contents and selecting items to archive",
          "strategy": "Examine each item in working_memory, evaluate its importance and relevance, then selectively move less critical items to storage while preserving essential information",
          "instructions": "When in paging mode: 1) Analyze all items currently in working_memory, 2) Identify which items are less critical or can be summarized, 3) Use storage_save to archive selected items with descriptive tags, 4) Use working_memory_remove to clean up archived items, 5) Keep only the most relevant and active information in working_memory. Always respond with valid XML containing an 'agent' tag with 'action' for memory management operations.",
          "state_description": {
            "paging": "Examine working_memory contents and intelligently select items to archive to storage. Prioritize keeping recent, active, and task-relevant information while archiving older thinking logs, completed subtasks, and reference data."
          },
          "selection_criteria": {
            "keep_in_memory": ["current todo items", "active character information", "recent thinking logs", "ongoing tasks", "immediate context"],
            "archive_to_storage": ["old thinking logs (>3 entries ago)", "completed subtasks", "reference information", "historical context", "processed data"]
          },
          "output_example_case1": {
            "comment": "LLM examines working_memory and decides to archive old thinking logs",
            "agent": {
              "action": {
                "type": "storage_save",
                "tags": "archived_thinking_session_001",
                "value": "Early thinking logs: Initial character setup for Alice (adventurous, nature-loving), brainstormed story directions, considered adding more characters to reach goal of 10."
              }
            }
          },
          "output_example_case2": {
            "comment": "LLM removes the archived item from working memory",
            "agent": {
              "action": {
                "type": "working_memory_remove",
                "tags": "thinking_log_00"
              }
            }
          },
          "output_example_case3": {
            "comment": "LLM archives character details that are now stable",
            "agent": {
              "action": {
                "type": "storage_save",
                "tags": "character_profiles_established",
                "value": "Alice: female, 25, adventurous, loves nature. Charlie: male, 28, easygoing, enjoys hiking. Both characters now have established backgrounds."
              }
            }
          },
          "output_example_case4": {
            "comment": "LLM preserves current todo while archiving completed analysis",
            "agent": {
              "action": {
                "type": "storage_save",
                "tags": "completed_character_analysis",
                "value": "Analyzed existing characters Alice and Charlie. Determined need for additional characters to meet 'Add characters until 10' requirement. Character development strategy established."
              }
            }
          },
          "output_example_case5": {
            "comment": "LLM adds a summary of cleanup actions taken",
            "agent": {
              "action": {
                "type": "working_memory_add",
                "tags": "paging_summary",
                "value": "Memory cleanup completed. Archived old thinking logs and character analysis. Working memory now optimized for continuing character development task."
              }
            }
          }
        }
      }
    }
  },
  "documentation": {
    "paging_system": {
      "description": "LLM-driven memory management system that activates when working memory approaches token limits",
      "trigger_conditions": {
        "paging_limit_reached": "When estimated tokens >= paging_limit (1024), system transitions to paging mode",
        "hard_limit_reached": "When estimated tokens >= hard_limit (2048), system forces paging mode immediately"
      },
      "llm_driven_approach": {
        "analysis_phase": "LLM examines all items currently in working_memory",
        "decision_making": "LLM evaluates importance, relevance, and recency of each item",
        "selection_process": "LLM chooses which items to archive based on context and task requirements",
        "intelligent_summarization": "LLM creates meaningful summaries when archiving multiple related items"
      },
      "paging_strategies": {
        "contextual_analysis": "LLM analyzes working memory content to understand current context",
        "smart_selection": "LLM selects items to archive based on importance and relevance",
        "intelligent_summarization": "LLM combines related items into coherent summaries before archiving",
        "preserve_context": "LLM maintains task continuity by keeping essential information active"
      },
      "example_workflow": {
        "step1": "Working memory reaches 1024+ tokens",
        "step2": "System auto-transitions from 'executing' to 'paging'",
        "step3": "LLM analyzes working memory: todo, character_alice_about, thinking_log_00, thinking_log_01",
        "step4": "LLM decides: keep 'todo' (current task), archive old thinking logs",
        "step5": "LLM creates summary: 'Early session focused on Alice character development'",
        "step6": "LLM saves summary to storage with descriptive tag",
        "step7": "LLM removes archived items from working memory",
        "step8": "System auto-transitions back to 'thinking' mode",
        "step9": "LLM continues with optimized working memory"
      }
    }
  }
}