owner,name,full_name,description,stars,language,created_at,html_url
OpenTalker,SadTalker,OpenTalker/SadTalker,[CVPR 2023] SadTalkerÔºöLearning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation,13235,Python,2022-11-23T02:18:18Z,https://github.com/OpenTalker/SadTalker
bytedance,LatentSync,bytedance/LatentSync,Taming Stable Diffusion for Lip Sync!,4959,Python,2024-12-11T10:32:54Z,https://github.com/bytedance/LatentSync
yerfor,GeneFace,yerfor/GeneFace,GeneFace: Generalized and High-Fidelity 3D Talking Face Synthesis; ICLR 2023; Official code,2635,Python,2023-02-03T13:52:50Z,https://github.com/yerfor/GeneFace
Weizhi-Zhong,IP_LAP,Weizhi-Zhong/IP_LAP,CVPR2023 talking face implementation for Identity-Preserving Talking Face Generation With Landmark and Appearance Priors,733,Python,2023-03-21T04:12:32Z,https://github.com/Weizhi-Zhong/IP_LAP
yerfor,GeneFacePlusPlus,yerfor/GeneFacePlusPlus,GeneFace++: Generalized and Stable Real-Time 3D Talking Face Generation; Official Code,1758,Python,2024-02-01T05:28:57Z,https://github.com/yerfor/GeneFacePlusPlus
JOY-MM,JoyGen,JOY-MM/JoyGen,talking-face video editing,381,Python,2025-01-02T05:41:08Z,https://github.com/JOY-MM/JoyGen
Hangz-nju-cuhk,Talking-Face_PC-AVS,Hangz-nju-cuhk/Talking-Face_PC-AVS,Code for Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation (CVPR 2021),951,Python,2021-03-25T08:31:36Z,https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS
OpenTalker,StyleHEAT,OpenTalker/StyleHEAT,[ECCV 2022] StyleHEAT: A framework for high-resolution editable talking face generation,656,Python,2022-03-09T06:42:59Z,https://github.com/OpenTalker/StyleHEAT
zhangchenxu528,FACIAL,zhangchenxu528/FACIAL,"FACIAL: Synthesizing Dynamic Talking Face With Implicit Attribute Learning. ICCV, 2021.",384,Python,2021-10-11T05:02:28Z,https://github.com/zhangchenxu528/FACIAL
yerfor,MimicTalk,yerfor/MimicTalk,MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes; NeurIPS 2024; Official code,777,Python,2024-10-09T10:02:04Z,https://github.com/yerfor/MimicTalk
ajay-sainy,Wav2Lip-GFPGAN,ajay-sainy/Wav2Lip-GFPGAN,High quality Lip sync,1137,Python,2022-08-18T03:11:21Z,https://github.com/ajay-sainy/Wav2Lip-GFPGAN
theEricMa,OTAvatar,theEricMa/OTAvatar,[CVPR2023] OTAvatar: One-shot Talking Face Avatar with Controllable Tri-plane Rendering.,324,Python,2023-03-09T06:10:42Z,https://github.com/theEricMa/OTAvatar
MStypulkowski,diffused-heads,MStypulkowski/diffused-heads,Official repository for Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation,487,Python,2023-01-10T12:48:47Z,https://github.com/MStypulkowski/diffused-heads
FuxiVirtualHuman,AAAI22-one-shot-talking-face,FuxiVirtualHuman/AAAI22-one-shot-talking-face,Code for One-shot Talking Face Generation from Single-speaker Audio-Visual Correlation Learning (AAAI 2022),358,Python,2022-03-01T06:38:21Z,https://github.com/FuxiVirtualHuman/AAAI22-one-shot-talking-face
MRzzm,HDTF,MRzzm/HDTF,"the dataset and code for ""Flow-guided One-shot Talking Face Generation with a High-resolution Audio-visual Dataset""",404,Python,2021-03-28T13:04:29Z,https://github.com/MRzzm/HDTF
yiranran,Audio-driven-TalkingFace-HeadPose,yiranran/Audio-driven-TalkingFace-HeadPose,"Code for ""Audio-driven Talking Face Video Generation with Learning-based Personalized Head Pose"" (Arxiv 2020) and ""Predicting Personalized Head Movement From Short Video and Speech Signal"" (TMM 2022)",766,Python,2020-03-01T05:25:03Z,https://github.com/yiranran/Audio-driven-TalkingFace-HeadPose
uniBruce,Mead,uniBruce/Mead,MEAD: A Large-scale Audio-visual Dataset for Emotional Talking-face Generation [ECCV2020],271,Python,2021-01-28T08:39:06Z,https://github.com/uniBruce/Mead
sahilg06,EmoGen,sahilg06/EmoGen,"PyTorch Implementation for Paper ""Emotionally Enhanced Talking Face Generation"" (ICCVW'23 and ACM-MMW'23)",376,Python,2023-03-23T18:39:33Z,https://github.com/sahilg06/EmoGen
Zz-ww,SadTalker-Video-Lip-Sync,Zz-ww/SadTalker-Video-Lip-Sync,Êú¨È°πÁõÆÂü∫‰∫éSadTalkersÂÆûÁé∞ËßÜÈ¢ëÂîáÂΩ¢ÂêàÊàêÁöÑWav2lip„ÄÇÈÄöËøá‰ª•ËßÜÈ¢ëÊñá‰ª∂ÊñπÂºèËøõË°åËØ≠Èü≥È©±Âä®ÁîüÊàêÂîáÂΩ¢ÔºåËÆæÁΩÆÈù¢ÈÉ®Âå∫ÂüüÂèØÈÖçÁΩÆÁöÑÂ¢ûÂº∫ÊñπÂºèËøõË°åÂêàÊàêÂîáÂΩ¢Ôºà‰∫∫ËÑ∏ÔºâÂå∫ÂüüÁîªÈù¢Â¢ûÂº∫ÔºåÊèêÈ´òÁîüÊàêÂîáÂΩ¢ÁöÑÊ∏ÖÊô∞Â∫¶„ÄÇ‰ΩøÁî®DAIN ÊèíÂ∏ßÁöÑDLÁÆóÊ≥ïÂØπÁîüÊàêËßÜÈ¢ëËøõË°åË°•Â∏ßÔºåË°•ÂÖÖÂ∏ßÈó¥ÂêàÊàêÂîáÂΩ¢ÁöÑÂä®‰ΩúËøáÊ∏°Ôºå‰ΩøÂêàÊàêÁöÑÂîáÂΩ¢Êõ¥‰∏∫ÊµÅÁïÖ„ÄÅÁúüÂÆû‰ª•ÂèäËá™ÁÑ∂„ÄÇ,1982,Python,2023-04-13T06:43:06Z,https://github.com/Zz-ww/SadTalker-Video-Lip-Sync
liutaocode,talking_face_preprocessing,liutaocode/talking_face_preprocessing,Preprocessing Scipts for Talking Face Generation,90,Python,2024-03-12T07:34:33Z,https://github.com/liutaocode/talking_face_preprocessing
Spycsh,xtalker,Spycsh/xtalker,Faster Talking Face Animation on Xeon CPU,130,Python,2023-06-26T08:20:07Z,https://github.com/Spycsh/xtalker
eeskimez,emotalkingface,eeskimez/emotalkingface,"The code for the paper ""Speech Driven Talking Face Generation from a Single Image and an Emotion Condition""",172,Python,2021-05-26T18:05:14Z,https://github.com/eeskimez/emotalkingface
jixinya,EAMM,jixinya/EAMM,Code for paper 'EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model',197,Python,2022-08-04T18:28:31Z,https://github.com/jixinya/EAMM
semchan,HyperLips,semchan/HyperLips,"Pytorch official implementation for our paper ""HyperLips: Hyper Control Lips with High Resolution Decoder for Talking Face Generation"".",212,Python,2023-10-10T03:40:38Z,https://github.com/semchan/HyperLips
saifhassan,Wav2Lip-HD,saifhassan/Wav2Lip-HD,High-Fidelity Lip-Syncing with Wav2Lip and Real-ESRGAN,488,Python,2023-04-02T14:14:30Z,https://github.com/saifhassan/Wav2Lip-HD
Moon0316,T2A,Moon0316/T2A,"Project page for ""Improving Few-shot Learning for Talking Face System with TTS Data Augmentation"" for ICASSP2023",86,Python,2022-10-18T07:54:22Z,https://github.com/Moon0316/T2A
ahaliassos,RealForensics,ahaliassos/RealForensics,Official code for Leveraging Real Talking Faces via Self-Supervision for Robust Forgery Detection (CVPR 2022),100,Python,2022-10-11T12:09:24Z,https://github.com/ahaliassos/RealForensics
AaronComo,LipFD,AaronComo/LipFD,"[NeurIPS 2024] This is the official repo of the paper ""Lips Are Lying: Spotting the Temporal Inconsistency between Audio and Visual in Lip-syncing DeepFakes"".",123,Python,2024-01-09T11:29:41Z,https://github.com/AaronComo/LipFD
Nota-NetsPresso,nota-wav2lip,Nota-NetsPresso/nota-wav2lip,A 28√ó Compressed Wav2Lip for Efficient Talking Face Generation [ICCV'23 Demo] [MLSys'23 Workshop] [NVIDIA GTC'23],57,Python,2024-02-07T06:55:20Z,https://github.com/Nota-NetsPresso/nota-wav2lip
Rudrabha,Wav2Lip,Rudrabha/Wav2Lip,"This repository contains the codes of ""A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild"", published at ACM Multimedia 2020. For HD commercial model, please try out Sync Labs ",12445,Python,2020-08-07T08:06:38Z,https://github.com/Rudrabha/Wav2Lip
deepkyu,ml-talking-face,deepkyu/ml-talking-face,Cloned repository from Hugging Face Spaces (CVPR 2022 Demo),53,Python,2022-07-14T02:08:55Z,https://github.com/deepkyu/ml-talking-face
mowshon,lipsync,mowshon/lipsync,"lipsync is a simple and updated Python library for lip synchronization, based on Wav2Lip. It synchronizes lips in videos and images based on provided audio, supports CPU/CUDA, and uses caching for faster processing.",133,Python,2020-10-22T13:56:44Z,https://github.com/mowshon/lipsync
wladradchenko,wunjo.wladradchenko.ru,wladradchenko/wunjo.wladradchenko.ru,"Wunjo CE: Face Swap, Lip Sync, Control Remove Objects & Text & Background, Restyling, Audio Separator, Clone Voice, Video Generation. Open Source, Local & Free.",1063,Python,2023-04-26T05:44:09Z,https://github.com/wladradchenko/wunjo.wladradchenko.ru
facefusion,facefusion,facefusion/facefusion,Industry leading face manipulation platform,25310,Python,2023-08-17T19:59:55Z,https://github.com/facefusion/facefusion
carykh,lazykh,carykh/lazykh,Source code for the automatic lip-syncing project described in this video! https://www.youtube.com/watch?v=y3B8YqeLCpY,363,Python,2022-05-14T17:05:07Z,https://github.com/carykh/lazykh
ShmuelRonen,ComfyUI-LatentSyncWrapper,ShmuelRonen/ComfyUI-LatentSyncWrapper,This node provides lip-sync capabilities in ComfyUI using ByteDance's LatentSync model. It allows you to synchronize video lips with audio input.,903,Python,2025-01-01T19:06:20Z,https://github.com/ShmuelRonen/ComfyUI-LatentSyncWrapper
CVI-SZU,DEGSTalk,CVI-SZU/DEGSTalk,[ICASSP'25]  DEGSTalk: Decomposed Per-Embedding Gaussian Fields for Hair-Preserving Talking Face Synthesis,50,Python,2024-12-24T14:56:38Z,https://github.com/CVI-SZU/DEGSTalk
ShmuelRonen,ComfyUI_wav2lip,ShmuelRonen/ComfyUI_wav2lip, A custom node for ComfyUI that allows you to perform lip-syncing on videos using the Wav2Lip model. It takes an input video and an audio file and generates a lip-synced output video.,142,Python,2024-05-13T14:22:34Z,https://github.com/ShmuelRonen/ComfyUI_wav2lip
guanjz20,StyleSync_PyTorch,guanjz20/StyleSync_PyTorch,"PyTorch implementation of ""StyleSync: High-Fidelity Generalized and Personalized Lip Sync in Style-based Generator""",214,Python,2023-06-25T07:40:35Z,https://github.com/guanjz20/StyleSync_PyTorch
AnimaVR,NeuroSync_Player,AnimaVR/NeuroSync_Player,The NeuroSync Player allows for real-time streaming of facial blendshapes into Unreal Engine 5 using LiveLink - enabling facial animation from audio input.,125,Python,2024-10-10T19:25:11Z,https://github.com/AnimaVR/NeuroSync_Player
ZiqiaoPeng,SyncTalk_2D,ZiqiaoPeng/SyncTalk_2D,A 2D customized lip-sync model for high-fidelity real-time driving.,85,Python,2025-06-25T02:11:46Z,https://github.com/ZiqiaoPeng/SyncTalk_2D
guanjz20,StyleSync,guanjz20/StyleSync,"Official code of CVPR '23 paper ""StyleSync: High-Fidelity Generalized and Personalized Lip Sync in Style-based Generator""",323,Python,2023-05-05T16:02:24Z,https://github.com/guanjz20/StyleSync
Inferencer,LipSick,Inferencer/LipSick,"ü§¢ LipSick: Fast, High Quality, Low Resource Lipsync Tool ü§Æ",217,Python,2024-04-23T11:53:59Z,https://github.com/Inferencer/LipSick
SamKhoze,ComfyUI-DeepFuze,SamKhoze/ComfyUI-DeepFuze,"DeepFuze is a state-of-the-art deep learning tool that seamlessly integrates with ComfyUI to revolutionize facial transformations, lipsyncing, Face Swapping, Lipsync Translation, video generation, and voice cloning.",434,Python,2024-06-13T02:25:50Z,https://github.com/SamKhoze/ComfyUI-DeepFuze
langzizhixin,wav2lip-576x576,langzizhixin/wav2lip-576x576,"This is a project about talking faces. We use 576X576 sized facial images for training, which can generate 2k, 4k, 6k, and 8k digital human  videos.",54,Python,2024-03-06T08:23:32Z,https://github.com/langzizhixin/wav2lip-576x576
pawansharmaaaa,Lip_Wise,pawansharmaaaa/Lip_Wise,"Orchestrating AI for stunning lip-synced videos. Effortless workflow, exceptional results, all in one place.",75,Python,2023-12-30T06:54:20Z,https://github.com/pawansharmaaaa/Lip_Wise
AnimaVR,NeuroSync_Local_API,AnimaVR/NeuroSync_Local_API,NeuroSync Audio to face animation local inference helper code.,72,Python,2024-10-16T19:57:56Z,https://github.com/AnimaVR/NeuroSync_Local_API
Flyworks-AI,flyworks-mcp,Flyworks-AI/flyworks-mcp,Fast and free zeroshot lipsync MCP server,90,Python,2025-05-06T12:03:15Z,https://github.com/Flyworks-AI/flyworks-mcp
yuvraj108c,ComfyUI-FLOAT,yuvraj108c/ComfyUI-FLOAT,Generative Motion Latent Flow Matching for Audio-driven Talking Portrait,235,Python,2025-05-06T11:46:21Z,https://github.com/yuvraj108c/ComfyUI-FLOAT
NVIDIA,Audio2Face-3D-Samples,NVIDIA/Audio2Face-3D-Samples,A service to convert audio to facial blendshapes for lipsyncing and facial performances. ,143,Python,2024-12-03T02:14:53Z,https://github.com/NVIDIA/Audio2Face-3D-Samples
xg-chu,ARTalk,xg-chu/ARTalk,"ARTalk generates realistic 3D head motions (lip sync, blinking, expressions, head poses) from audio in ‚ö° real-time ‚ö°.",90,Python,2025-03-03T14:55:42Z,https://github.com/xg-chu/ARTalk
instant-high,wav2lip-onnx-HQ,instant-high/wav2lip-onnx-HQ,Full version of wav2lip-onnx including face alignment and face enhancement and more...,139,Python,2024-03-18T16:03:02Z,https://github.com/instant-high/wav2lip-onnx-HQ
blackears,parrotLipsync,blackears/parrotLipsync,Addon for Blender that lets you generate lipsync animation automatically from audio files.,64,Python,2023-12-25T07:05:24Z,https://github.com/blackears/parrotLipsync
numz,wav2lip_uhq,numz/wav2lip_uhq,Wav2Lip UHQ Improvement with ControlNet 1.1,74,Python,2023-05-12T04:12:46Z,https://github.com/numz/wav2lip_uhq
numz,sd-wav2lip-uhq,numz/sd-wav2lip-uhq,Wav2Lip UHQ extension for Automatic1111,1409,Python,2023-08-03T12:37:16Z,https://github.com/numz/sd-wav2lip-uhq
lukerbs,pytoon,lukerbs/pytoon,"PyToon is a Python based animation library for automatically animating a cartoon character's mouth movements and bodily expressions to sync with an audio recording of someone talking. PyToon uses machine learning based audio analysis techniques to automatically generate lip-synced character animations (see ""Example Output Video"" in README).",50,Python,2024-03-25T17:48:55Z,https://github.com/lukerbs/pytoon
